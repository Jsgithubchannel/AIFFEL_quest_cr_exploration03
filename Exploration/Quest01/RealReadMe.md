### 종합 회고

## 느낀 점
- 테스트 데이터를 포함한 전체 학습 이미지가 특정한 패턴을 띠고 있었고, 이에 따라 모델 테스트 정확도도 높게 나오는 반면 외부 이미지를 예측했을 때 잘못된 분류를 반복하였다. 서비스 측면에서 '이파리 한 장을 떼어 촬영하세요' 등 조건을 명시할 수도 있겠지만 모델 학습 입장에서는 증강을 거친다던지 좀 더 고도화된 작업을 거쳐야 실사용에 쓸만한 작업 결과를 얻을 수 있었을 것 같았다. 종합적으로 모델의 성능을 어떻게 평가할 것인지 고민이 좀 더 필요하다고 생각되었다.

## 데이터셋
- 사용한 데이터셋: https://www.tensorflow.org/datasets/catalog/plant_village
- 원활한 학습을 위해 이미지 크기를 160*160으로 리사이징함
- image = (image/127.5) - 1 을 적용하여 픽셀값을 -1 ~ 1로 조정함

## 모델
- 사용한 모델: 전이학습 없이 Conv층을 sequential 구조로 사용함
- ![image](https://github.com/user-attachments/assets/5bf087c2-e7e6-4bea-b808-517dfb0069fd)

## 테스트 정확도
- 테스트 데이터셋 정확도: 0.9403 달성함
- 데이터셋 이미지 대부분이 이파리 한 장을 떼어내 깔끔하게 찍혀있는 사진들로 이루어져있음(테스트 데이터셋도 마찬가지)
- 이 때문인지 배경이 복잡한 외부 이미지를 predict했을 때 정확하지 않은 결과가 출력됨(= 모델이 해당 패턴을 과하게 암기함)
- 모델 성능을 발전시키려면 augment를 적용하거나 사전학습 모델을 불러오는 등의 작업을 진행해 볼 수 있을 것 같음

## 모델 저장 및 서버 로드
- app.py 코드에 모델을 로드하여 로컬호스트에 연결하였음
- 모델학습 및 데이터셋 로드를 클라우드에서 진행하였는데, 서버 코드 및 모델 디렉토리는 로컬에서 진행하였음
- 이 때문에 서버 코드에서 class_names를 직접 명시해야 했음 -> 데이터셋을 따로 받아와서 간단하게 진행하는 방법이 있었을 것 같음
- url을 POST하면 모델에서 예측결과를 반환하는 엔드포인트와, 해당 url 이미지를 앱에 같이 띄우도록 하는 엔드포인트를 작성하였음

## 앱 구현
- 앱은 한 페이지 내에서 url을 입력할 수 있는 Textfield, 해당 url의 이미지 표시, 예측 요청 전송하는 버튼으로 간단하게만 구성하였음
- 예측시 _confidence * 100에 해당하는 값을 함께 출력하여 이미지를 어느정도 확신도로 예측하였는지 확인하게 하였음
- 발전시킨다면 카메라 연동 기능을 추가하면 좋을 것 같음
- ![image](https://github.com/user-attachments/assets/11031ceb-87b9-4faa-846f-34053f149ef0)
